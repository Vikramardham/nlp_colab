# Illustration of various NLP architectures in classifying text
----
+ A multi-label text classification problem is shown Implementations of Vanilla-RNN and GRU models are shown (from scracth in PyTorch)
+ A handy training module has been implemented, it allows logging, tensorboard, choosing schedulers, metrics and so on
+ In addition, usage of PyTorch LSTM and the fancy BERT model have been shown here too.
+ Tokenization procedures in Keras and spaCy shown
+ This work is focused on solving the text-classification problem using various state-of-the-art architectures. Hyperparamter tuning has not been done, but can be done in just a couple of iterations with already promising performance.
+ Computed on Google Colab.